# Архитектура, пайплайн и использование pandas/matplotlib

## Общее устройство проекта
- Пакет `lw3` — модульный набор компонентов для анализа CSV-датасетов CORGIS: утилиты, пайплайн чтения, визуализация и задачи по конкретным датасетам.
- Основные подсистемы:
  - `lw3/pipeline.py` — генераторный пайплайн чтения CSV чанками.
  - `lw3/utils.py` — вспомогательные функции: поиск столбцов, статистика Вэлфорда, CI, скользящее среднее, создание директорий.
  - `lw3/plots.py` — единообразная визуализация баров, линий и scatter-плотов.
  - `lw3/parquet_utils.py` — конвертация CSV → Parquet и сравнение быстродействия чтения.
  - `lw3/datasets/` — задачи и графики для каждого датасета: Airlines, Weather, Video Games, Global Emissions, Business Dynamics.
  - `lw3/run_all.py` — единая orchestration: подготовка Parquet, запуск анализов, дополнительные задания.

## Пайплайн и генератор
- Ключевой элемент — генератор `read_csv_chunks` (`lw3/pipeline.py:9`), который вызывает `pandas.read_csv(..., chunksize=...)` и возвращает поток чанков `DataFrame`.
- Обработка ведется в циклах по чанкам, без загрузки всего файла в память; это снижает требования к ОЗУ и улучшает масштабируемость.
- Композиция генераторов (например, `pass_through`) позволяет строить простые конвейеры для последующей обработки (агрегации, группировки, расчётов).
- Когда нужно целиком файл (например, для Parquet сравнения), применяется прямое чтение без генератора, что явно отмечено в коде.

## Конфигурация стиля и проверка flake8
- Добавлен конфигурационный файл `.flake8` с параметрами:
  - `max-line-length = 260` — допускает длинные строки для читаемых титулов графиков/сводок.
  - `extend-ignore = W292` — игнорирует отсутствие завершающей пустой строки, учитывая особенности среды.
- Исправлены замечания по стилю: лишние пробелы в срезах (`E203`), неиспользуемые импорты, неоднозначные имена переменных, добавлены докстринги.

## Использование pandas и приёмы обработки
- Типовая схема по чанку:
  - Приведение типов: `pd.to_numeric(..., errors="coerce").fillna(0)` для числовых столбцов.
  - Группировки: `df.groupby(...).sum()/mean()/agg(...)` для месячных/годовых/категориальных агрегаций.
  - Вычисления метрик: доли, средние, стандартное отклонение (алгоритм Вэлфорда), скользящее среднее `rolling(...).mean()`.
  - Корреляции: `pd.Series(x).corr(pd.Series(y))`.
- По датасетам:
  - Airlines (`lw3/datasets/airlines.py`):
    - Приведение типов для `delayed`, `cancelled`, `total`.
    - Агрегация по месяцам, расчёт доли `(delayed + cancelled) / total` с CI95 по годам-месяцам.
    - Разброс доли по аэропортам: обновление `Welford` на потоковых значениях по чанкам.
    - Временные ряды по аэропортам: группировка по `(airport, year, month)` и суммирование.
    - Корреляция `delayed+cancelled` vs `total`.
  - Weather (`lw3/datasets/weather.py`):
    - Поиск колонок по ключевым словам, приведение типов для `temp_avg`, `wind`, `prec`.
    - Средняя температура по локациям: `groupby(location).agg(sum,count)` и разделение для итогов.
    - Разброс среднемесячной температуры по штатам — потоковое обновление `Welford`.
    - Самый ветреный штат: средние по `wind` и временной ряд `(state, year, month)`; скользящее среднее.
    - Доп. корреляция `wind` vs `precip`.
  - Video Games (`lw3/datasets/video_games.py`):
    - Продажи по годам: `groupby(year).sum()`.
    - Разброс оценок по издателям: `Welford` по `review`.
    - Количество игр по рейтингу: `groupby([year, rating]).sum()` счётчика.
    - Корреляция `review` vs `sales`.
  - Global Emissions (`lw3/datasets/global_emissions.py`):
    - Выбросы на душу: агрегация `emissions` и `population` по странам, расчет отношения.
    - Разброс суммарных выбросов по странам: `Welford` по `emissions`.
    - Суммарные `GDP` и `emissions` как сводные метрики.
    - Корреляция `population` vs `emissions`.
  - Business Dynamics (`lw3/datasets/business_dynamics.py`):
    - Средний `Net Job Creation Rate` по штатам (сумма/число наблюдений).
    - Разброс `Reallocation Rate` — `Welford`.
    - Динамика `Job Destruction Rate` по интересующему штату: `groupby([state, year]).mean()` и временной ряд.
    - Корреляция `JCR` vs `JDR`.

## Визуализация с matplotlib
- Единый слой `lw3/plots.py` обеспечивает удобные вызовы:
  - `save_bar(labels, values, ...)` — бар-чарты с авто-пагинацией больших наборов (разбиение на части), опциональные доверительные интервалы (`errorbar`).
  - `_save_bar_single(...)` — внутренний помощник, автоматически выбирает горизонтальную ориентацию при большом числе меток и регулирует размеры фигуры.
  - `save_line(labels, values, ...)` — линейные графики для временных рядов.
  - `save_scatter(x, y, ...)` — scatter для визуализации корреляций.
- Отрисовка сохраняет файлы в `lw3/output/...` с аккуратной версткой (`tight_layout`), читаемыми осями и сеткой.

## Parquet и производительность
- `lw3/parquet_utils.py`:
  - `ensure_parquet(csv_path, parquet_path)` — создаёт Parquet из CSV, при необходимости создаёт директорию.
  - `compare_read_speed(csv_path, parquet_path)` — замеряет время чтения CSV и Parquet целиком.
- `lw3/run_all.py` фиксирует результаты в `output/perf_*.txt` и строит дополнительные scatter-плоты, читая только релевантные столбцы из Parquet (`pd.read_parquet(..., columns=[...])`).

## Оркестрация `run_all`
- Объявлены пути `BASE/CACHE/DATA/OUT`.
- Подготовка Parquet для каждого датасета и замеры производительности.
- Запуск `run_all(...)` для каждого набора и генерация графиков + сводок.
- Дополнительные задания: построение scatter-графиков из Parquet по релевантным столбцам (Airlines, Weather, Video Games, Global Emissions, Business Dynamics).

## Поиск столбцов и удобство
- Функции `find_first_match` и `find_all_matches` нормализуют имена столбцов и позволяют устойчиво искать нужные поля по ключевым словам (не зависят от регистра, разделителей и вариаций имен).
- Это снижает хрупкость к изменению схемы CSV и упрощает переносимость решений между датасетами.

## Резюме
- Архитектура разделяет ответственность: чтение данных, вычисления, визуализация, подготовка форматов и оркестрация.
- Пайплайн на генераторах обеспечивает экономичную обработку больших CSV.
- Единые утилиты и визуализация повышают согласованность и снижают дублирование кода.